# -*- coding: utf-8 -*-
"""Gastric Cancer Main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lirSGwL9cKyPs7xMFRuTxmMB1HYLzX5S
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import random
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.models as models
import torchvision.transforms as transforms
from torchvision.transforms import functional as F

device=torch.device("cuda"if torch.cuda.is_available()else"cpu")
from google.colab import drive
drive.mount('/content/drive')
test_image_path = "/content/drive/MyDrive/Trivial Files/test_images"

#Load U-Net
!pip install segmentation-models-pytorch --quiet

import segmentation_models_pytorch as smp
U_Net = smp.Unet(
    encoder_name="resnet34",
    encoder_weights="imagenet",
    in_channels=3,
    classes=1
)

U_Net = U_Net.to(device)
U_Net.load_state_dict(torch.load("/content/drive/MyDrive/AI_Models/U_Net.pth"))
U_Net.eval()

#Load ResNet
class CancerClassifier(nn.Module):
  def __init__(self, num_classes=3):
    super(CancerClassifier, self).__init__()
    self.resnet = models.resnet18(pretrained=True)
    self.resnet.conv1 = nn.Conv2d(
      in_channels=4,
      out_channels=64,
      kernel_size=7,
      stride=2,
      padding=3,
      bias=False
    )

    in_features = self.resnet.fc.in_features
    self.resnet.fc = nn.Linear(in_features, num_classes)

  def forward(self, x):
    return self.resnet(x)

ResNet = CancerClassifier(num_classes=3).to(device)
ResNet.load_state_dict(torch.load("/content/drive/MyDrive/AI_Models/ResNet.pth"))
ResNet.eval()

# image → mask → (image+mask) → label
class_names = ["Normal", "CancerType1", "CancerType2"]
transform = transforms.Compose([
    transforms.Resize((512,512)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])
])

def prediction_and_visualisation(test_image_path, U_Net, ResNet, device, class_names):
  # 1. 读取 & 预处理原图
  image = Image.open(test_image_path).convert("RGB")
  image_tensor = transform(image).unsqueeze(0).to(device)  # [1,3,H,W]

  # 2. U-Net 预测 mask
  with torch.no_grad():
    pred_mask = U_Net(image_tensor)  # [1,1,H,W]
    pred_mask = torch.sigmoid(pred_mask)
    pred_mask = (pred_mask > 0.5).float()  # 二值化
    pred_mask_bin = pred_mask.cpu().squeeze().numpy()

  # 3. 拼接原图 + mask
  combined_input = torch.cat([image_tensor, pred_mask], dim=1)  # [1,4,H,W]

  # 4. ResNet 分类
  with torch.no_grad():
    #ResNet 输出的是一个向量 [1, num_classes]，每个数可以是任意实数（logits）
    logits = ResNet(combined_input)
    probs = torch.softmax(logits, dim=1)
    pred_class = torch.argmax(probs, dim=1).item()  #.item() 把 Tensor 转成普通 Python 数字

  # 5. 标签对应类别名称
  if class_names:
    pred_label = class_names[pred_class]
  else:
    pred_label = f"Class {pred_class}"

  # 6. 可视化
  fig, axes = plt.subplots(1, 3, figsize=(12,4))

  # 原图
  axes[0].imshow(image)
  axes[0].set_title("Original Image")
  axes[0].axis("off")

  # Mask
  axes[1].imshow(pred_mask_bin, cmap="gray")
  axes[1].set_title("Predicted Mask")
  axes[1].axis("off")

  # 分类结果
  axes[2].imshow(image)
  axes[2].set_title(f"Classification: {pred_label}")
  axes[2].axis("off")

  plt.show()
  return pred_class, probs.cpu().numpy()

pred_class, probs = prediction_and_visualisation(test_image_path, U_Net, ResNet, device, class_names)

print(f"Predicted Class: {class_names[pred_class]} ({pred_class})")
for i, cls in enumerate(class_names):
  print(f"{cls}: {probs[0][i]:.4f}")
#probs 是 softmax 后的概率分布，形状 [1, num_classes]，所以 probs[0][i] 表示第 0 张图片的第 i 类概率