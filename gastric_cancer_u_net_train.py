# -*- coding: utf-8 -*-
"""Gastric Cancer U-Net Train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pHcvZgcjBReBOHPiPHq-DPQxxDUKOPnp
"""

import os
import pandas as pd
from PIL import Image
import random
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.transforms import functional as F

from google.colab import drive
drive.mount('/content/drive')

image_dir = "/content/drive/MyDrive/Trivial Files/train_org_image_100"
mask_dir = "/content/drive/MyDrive/Trivial Files/train_mask_100"
excel_file = "/content/drive/MyDrive/Trivial Files/train_label.csv"

class HistopathologyDataset(Dataset):
  def __init__(self, image_dir, mask_dir, excel_file, image_transform=None, mask_transform=None, augmentation=None):
    """
    image_dir: 原图路径
    mask_dir: mask路径
    excel_file: Excel路径（包含 image_name 和 label 列）
    image_transform: 对image的预处理
    mask_transform: 对mask的预处理
    augmentation: 数据增广
    """
    self.image_dir = image_dir
    self.mask_dir = mask_dir
    self.labels_df = pd.read_csv(excel_file)
    self.image_transform = image_transform
    self.mask_transform = mask_transform
    self.augmentation = augmentation

    valid_rows = []
    for _, row in self.labels_df.iterrows():
      img_path = os.path.join(image_dir, row['image_name'])
      mask_path = os.path.join(mask_dir, row['image_name'])
      if os.path.exists(img_path) and os.path.exists(mask_path):
        valid_rows.append(row)

    self.labels_df = pd.DataFrame(valid_rows).reset_index(drop=True)
    print(f"有效样本数: {len(self.labels_df)}")

  def __len__(self):
    return len(self.labels_df)

  def __getitem__(self, idx):
    row = self.labels_df.iloc[idx]
    img_name = row['image_name']
    label = row['label']

    img_path = os.path.join(self.image_dir, img_name)
    mask_path = os.path.join(self.mask_dir, img_name)

    image = Image.open(img_path).convert("RGB")
    mask = Image.open(mask_path).convert("L")

    #在PIL阶段做数据增强（保证同步）
    if self.augmentation:
      image, mask = self.augmentation(image, mask)

    if self.image_transform:
      image = self.image_transform(image)

    if self.mask_transform:
      mask = self.mask_transform(mask)

    # 确保mask是long类型（用于CrossEntropyLoss）
    mask = torch.where(mask > 0.5, 1, 0).long()
    return image, mask, label

#Padding
image_fill, mask_fill = 255, 0    # 对image补白边，对mask补黑边

class SquarePad:
  def __init__(self, fill):
    self.fill = fill

  def __call__(self, image):
    w, h = image.size
    max_wh = max(w, h)  # 取最长边
    # 左右上下要补多少
    hp = (max_wh - w) // 2
    vp = (max_wh - h) // 2
    padding = (hp, vp, max_wh - w - hp, max_wh - h - vp)
    return F.pad(image, padding, fill=self.fill, padding_mode="constant")

class Augmentation: #S4 对称群的轨道
  def __call__(self, image, mask):
    # 随机水平翻转
    if random.random() > 0.5:
      image = F.hflip(image)
      mask = F.hflip(mask)

    # 随机垂直翻转
    if random.random() > 0.5:
      image = F.vflip(image)
      mask = F.vflip(mask)

    # 随机旋转
    angle = random.choice([0, 90, 180, 270])
    image = F.rotate(image, angle)
    mask = F.rotate(mask, angle)

    return image, mask

if __name__ == "__main__":

  image_transform = transforms.Compose([
    transforms.Resize(512),
    SquarePad(fill=image_fill),
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])
  ])

    #括号内数字是ImageNet数据集的均值和标准差（分别统计RGB三个通道）。
    #大多数预训练模型（ResNet、ViT、DenseNet）都在ImageNet上训练，所以用同样的归一化方式，以对齐预训练权重。

  mask_transform = transforms.Compose([
    transforms.Resize(512, interpolation=Image.NEAREST),
    SquarePad(fill=mask_fill),
    transforms.Resize((512, 512), interpolation=Image.NEAREST),
    transforms.ToTensor()
  ])

  dataset = HistopathologyDataset(
        image_dir, mask_dir, excel_file,
        image_transform = image_transform,
        mask_transform = mask_transform,
        augmentation = Augmentation()
  )
  dataloader = DataLoader(dataset, batch_size=4, shuffle=True)


  for images, masks, labels in dataloader:
    print("Images:", images.shape)    # torch.Size([4, 3, 224, 224])
    print("Masks:", masks.shape)     # torch.Size([4, 1, 224, 224])  (二值 0/1)
    print("Labels:", labels)
    break

#Contructing U_Net (from image to mask)
!pip install segmentation-models-pytorch --quiet

import segmentation_models_pytorch as smp
U_Net = smp.Unet(
    encoder_name="resnet34",
    encoder_weights="imagenet",
    in_channels=3,
    classes=1
)
print(U_Net.__class__.__name__)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
U_Net = U_Net.to(device)

# BCEWithLogitsLoss 里会自动套一个 sigmoid，把 logit 压缩成概率，再和标签 0/1 比较
loss_fn = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(U_Net.parameters(), lr=0.0001)
num_epochs = 5
epoch_num = []
train_losses, dice_scores = [], []
from tqdm import tqdm  # 进度条

#Dice 函数（越接近 1 越好）
def dice_score(pred, target, eps=1e-6):
    """
    pred: [B, 1, H, W] (logits from model)
    target: [B, 1, H, W] (ground truth mask, float 0/1)
    """
    # 用 sigmoid 把 logits 映射到 [0,1]
    pred = torch.sigmoid(pred)
    pred = (pred > 0.5).float()  # 二值化

    intersection = (pred * target).sum(dim=(2,3))
    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))
    dice = (2. * intersection + eps) / (union + eps)

    return dice.mean().item()

# U_Net训练函数
def train_unet(U_Net, dataloader, optimizer, loss_fn, device, num_epochs):

  for epoch in range(num_epochs):
    U_Net.train()
    train_loss = 0.0
    train_dice = 0.0

    for images, masks, labels in tqdm(dataloader, desc=f"Train Epoch {epoch+1}/{num_epochs}"):
        images, masks = images.to(device), masks.to(device)

        optimizer.zero_grad()
        pred_masks = U_Net(images)  # [B, 1, H, W]
        loss = loss_fn(pred_masks, masks.float())

        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_dice += dice_score(pred_masks, masks.float())

    avg_loss = train_loss / len(dataloader)
    avg_dice = train_dice / len(dataloader)
    train_losses.append(avg_loss)
    dice_scores.append(avg_dice)
    epoch_num.append(epoch+1)

    print(f"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f} | Dice: {avg_dice:.4f}")

  return U_Net

trained_unet = train_unet(U_Net, dataloader, optimizer, loss_fn, device, num_epochs)

import matplotlib.pyplot as plt
plt.plot(epoch_num, train_losses)
plt.xlabel("Epoch Number")
plt.ylabel("Training Loss (BCEWithLogits)")
plt.title("Training Loss Curve")
plt.show()

plt.plot(epoch_num, dice_scores)
plt.xlabel("Epoch Number")
plt.ylabel("Dice Score")
plt.title("Dice Score Curve")
plt.show()

torch.save(trained_unet.state_dict(), "U_Net.pth")
!cp U_Net.pth /content/drive/MyDrive/AI_Models/
print("✅ Model saved as U_Net.pth to Google Drive")